{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0829fd66",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-16T07:55:34.070375Z",
     "iopub.status.busy": "2024-05-16T07:55:34.070022Z",
     "iopub.status.idle": "2024-05-16T07:55:34.759965Z",
     "shell.execute_reply": "2024-05-16T07:55:34.759198Z"
    },
    "papermill": {
     "duration": 0.701697,
     "end_time": "2024-05-16T07:55:34.762255",
     "exception": false,
     "start_time": "2024-05-16T07:55:34.060558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed39ba2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T07:55:34.778779Z",
     "iopub.status.busy": "2024-05-16T07:55:34.778367Z",
     "iopub.status.idle": "2024-05-16T07:55:34.783760Z",
     "shell.execute_reply": "2024-05-16T07:55:34.782886Z"
    },
    "papermill": {
     "duration": 0.015663,
     "end_time": "2024-05-16T07:55:34.785671",
     "exception": false,
     "start_time": "2024-05-16T07:55:34.770008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_image(image_path, IMG_SIZE=224):\n",
    "\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_image(image, channels=3, expand_animations= False)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba0f0f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T07:55:34.801484Z",
     "iopub.status.busy": "2024-05-16T07:55:34.801177Z",
     "iopub.status.idle": "2024-05-16T07:55:35.518585Z",
     "shell.execute_reply": "2024-05-16T07:55:35.517504Z"
    },
    "papermill": {
     "duration": 0.727068,
     "end_time": "2024-05-16T07:55:35.520178",
     "exception": true,
     "start_time": "2024-05-16T07:55:34.793110",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/forest-fire-dataset/Forest Fire Dataset/Training/nofire\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     images_loc\u001b[38;5;241m.\u001b[39mappend(\u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/forest-fire-dataset/Forest Fire Dataset/Training/nofire\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/forest-fire-dataset/Forest Fire Dataset/Training/fire\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m, in \u001b[0;36mprocess_image\u001b[0;34m(image_path, IMG_SIZE)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_image\u001b[39m(image_path, IMG_SIZE\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_file(image_path)\n\u001b[1;32m      4\u001b[0m     image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mdecode_image(image, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, expand_animations\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mconvert_image_dtype(image, tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "images_loc = []\n",
    "labels = []\n",
    "for i in os.listdir(\"/kaggle/input/forest-fire-dataset/Forest Fire Dataset/Training/nofire\"):\n",
    "    images_loc.append(process_image(\"/kaggle/input/forest-fire-dataset/Forest Fire Dataset/Training/nofire\"+\"/\"+i))\n",
    "    labels.append(0)\n",
    "for i in os.listdir(\"/kaggle/input/forest-fire-dataset/Forest Fire Dataset/Training/fire\"):\n",
    "    images_loc.append(process_image(\"/kaggle/input/forest-fire-dataset/Forest Fire Dataset/Training/fire\"+\"/\"+i))\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ed5f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T06:38:00.760549Z",
     "iopub.status.busy": "2024-05-16T06:38:00.760264Z",
     "iopub.status.idle": "2024-05-16T06:38:00.765171Z",
     "shell.execute_reply": "2024-05-16T06:38:00.764103Z",
     "shell.execute_reply.started": "2024-05-16T06:38:00.760517Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classnames = np.array([\"nofire\", \"fire\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448e5ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T06:38:01.291010Z",
     "iopub.status.busy": "2024-05-16T06:38:01.290182Z",
     "iopub.status.idle": "2024-05-16T06:38:02.512103Z",
     "shell.execute_reply": "2024-05-16T06:38:02.511269Z",
     "shell.execute_reply.started": "2024-05-16T06:38:01.290980Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_loc = np.array(images_loc)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9343cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T06:38:06.005623Z",
     "iopub.status.busy": "2024-05-16T06:38:06.004805Z",
     "iopub.status.idle": "2024-05-16T06:38:06.011269Z",
     "shell.execute_reply": "2024-05-16T06:38:06.010375Z",
     "shell.execute_reply.started": "2024-05-16T06:38:06.005591Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_loc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffafb99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T06:38:51.745647Z",
     "iopub.status.busy": "2024-05-16T06:38:51.744791Z",
     "iopub.status.idle": "2024-05-16T06:38:51.989017Z",
     "shell.execute_reply": "2024-05-16T06:38:51.988217Z",
     "shell.execute_reply.started": "2024-05-16T06:38:51.745604Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_testy, y_train, y_testy = train_test_split(images_loc, labels, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46a93d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T06:38:55.220076Z",
     "iopub.status.busy": "2024-05-16T06:38:55.219720Z",
     "iopub.status.idle": "2024-05-16T06:38:55.282547Z",
     "shell.execute_reply": "2024-05-16T06:38:55.281468Z",
     "shell.execute_reply.started": "2024-05-16T06:38:55.220050Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_testy, y_testy, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2d219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T06:38:58.366574Z",
     "iopub.status.busy": "2024-05-16T06:38:58.366206Z",
     "iopub.status.idle": "2024-05-16T06:38:58.372512Z",
     "shell.execute_reply": "2024-05-16T06:38:58.371559Z",
     "shell.execute_reply.started": "2024-05-16T06:38:58.366545Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec58a8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T06:58:32.799866Z",
     "iopub.status.busy": "2024-05-16T06:58:32.798984Z",
     "iopub.status.idle": "2024-05-16T06:58:32.805193Z",
     "shell.execute_reply": "2024-05-16T06:58:32.804266Z",
     "shell.execute_reply.started": "2024-05-16T06:58:32.799825Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_25_images(images):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        ax=plt.subplot(5,5,i+1)\n",
    "        plt.imshow(images[i])\n",
    "#         plt.title(classnames[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de971dad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T06:58:39.324421Z",
     "iopub.status.busy": "2024-05-16T06:58:39.324060Z",
     "iopub.status.idle": "2024-05-16T06:58:40.772281Z",
     "shell.execute_reply": "2024-05-16T06:58:40.771257Z",
     "shell.execute_reply.started": "2024-05-16T06:58:39.324392Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_25_images(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e6b2be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T06:37:14.873136Z",
     "iopub.status.busy": "2024-05-16T06:37:14.872315Z",
     "iopub.status.idle": "2024-05-16T06:37:27.374987Z",
     "shell.execute_reply": "2024-05-16T06:37:27.373963Z",
     "shell.execute_reply.started": "2024-05-16T06:37:14.873100Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, DepthwiseConv2D, Concatenate, Reshape, Lambda, UpSampling2D, Activation, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape, BatchNormalization, LSTM, Conv1D, MaxPooling1D, Conv2D, Input, Concatenate, Add, PReLU, AveragePooling2D\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168e079",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Using Custom cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3a583",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.065567Z",
     "iopub.status.idle": "2024-05-16T06:30:44.065999Z",
     "shell.execute_reply": "2024-05-16T06:30:44.065787Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.065769Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_cnn(X1, X2, X3):\n",
    "    inputs = Input(shape=(X1, X2, X3))\n",
    "    C1 = Conv2D(128, (5, 5), activation='relu', padding='valid')(inputs)\n",
    "    P1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(C1)\n",
    "    C2 = Conv2D(64, (3, 3), activation='relu', padding='same')(P1)\n",
    "    C3 = Conv2D(64, (3, 3), activation='relu', padding='same')(C2)\n",
    "    P2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(C3)\n",
    "    C4 = Conv2D(32, (3, 3), activation='relu', padding='same')(P2)\n",
    "    C5 = Conv2D(32, (3, 3), activation='relu', padding='same')(C4)\n",
    "    P3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(C5)\n",
    "    F1 = Flatten()(P3)\n",
    "    D1 = Dense(1024, activation='relu')(F1)\n",
    "    DR1 = Dropout(0.5)(D1)\n",
    "    D2 = Dense(512, activation='relu')(DR1)\n",
    "    DR2 = Dropout(0.5)(D2)\n",
    "    outputs = Dense(1, activation='sigmoid')(DR2)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d701028",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.067890Z",
     "iopub.status.idle": "2024-05-16T06:30:44.068224Z",
     "shell.execute_reply": "2024-05-16T06:30:44.068078Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.068064Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = custom_cnn(224,224,3)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "pred = m.fit(X_train, y_train,\n",
    "             batch_size=32,epochs=25,\n",
    "             validation_data=(X_val, y_val),\n",
    "             callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9652042d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.070034Z",
     "iopub.status.idle": "2024-05-16T06:30:44.070354Z",
     "shell.execute_reply": "2024-05-16T06:30:44.070216Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.070204Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = m.predict(X_test)\n",
    "binary_predictions = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6471f5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.071326Z",
     "iopub.status.idle": "2024-05-16T06:30:44.071676Z",
     "shell.execute_reply": "2024-05-16T06:30:44.071492Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.071479Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def results(y_test, y_pred):    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TP,TN,FP,FN = cm[0][0],cm[1][1],cm[0][1],cm[1][0]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    SE = TP / (TP + FN)\n",
    "    SP = TN / (TN + FP)\n",
    "    ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "    DSC = (2 * TP) / (2 * TP + FP + FN)\n",
    "    Precision = TP / (TP + FP)\n",
    "    Recall = TP / (TP + FN)\n",
    "    print(f\"SE: {SE:.2f}\")\n",
    "    print(f\"SP: {SP:.2f}\")\n",
    "    print(f\"ACC: {ACC:.2f}\")\n",
    "    print(f\"DSC: {DSC:.2f}\")\n",
    "    print(f\"Precision: {Precision:.2f}\")\n",
    "    print(f\"Recall: {Recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37f00d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.073348Z",
     "iopub.status.idle": "2024-05-16T06:30:44.073703Z",
     "shell.execute_reply": "2024-05-16T06:30:44.073547Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.073527Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results(y_test,binary_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b455ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## ATT Squeeze U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d2686",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.074763Z",
     "iopub.status.idle": "2024-05-16T06:30:44.075068Z",
     "shell.execute_reply": "2024-05-16T06:30:44.074929Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.074917Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def channel_shuffle(x, groups):\n",
    "    batch_size, height, width, channels = x.shape\n",
    "    channel_per_group = channels // groups\n",
    "    x = Reshape((height, width, groups, channel_per_group))(x)\n",
    "    x = tf.transpose(x, perm=[0, 1, 2, 4, 3])\n",
    "    x = Reshape((height, width, channels))(x)\n",
    "    return x\n",
    "\n",
    "def fire_module(x, s1, e1, e3):\n",
    "    s1x = Conv2D(s1, kernel_size=1, padding='same')(x)\n",
    "    s1x = ReLU()(s1x)\n",
    "    e1x = Conv2D(e1, kernel_size=1, padding='same')(s1x)\n",
    "    e3x = DepthwiseConv2D(kernel_size=3, padding='same')(s1x)\n",
    "    e3x = Conv2D(e3, kernel_size=1, padding='same')(e3x)\n",
    "    total_channels = e1 + e3\n",
    "    x = Concatenate()([e1x, e3x])\n",
    "    x = channel_shuffle(x, groups=2)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def defire_module(x, s1, e3):\n",
    "    # First 1x1 convolution\n",
    "    e1x = Conv2D(s1, kernel_size=(1, 1), padding='same')(x)\n",
    "    e1x = Activation('relu')(e1x)\n",
    "    \n",
    "    # First 3x3 convolution (without changing the number of filters)\n",
    "    e1x = Conv2D(s1, kernel_size=(3, 3), padding='same')(e1x)\n",
    "    e1x = Activation('relu')(e1x)\n",
    "    e3x = Conv2D(s1, kernel_size=(3, 3), padding='same')(e1x)\n",
    "    e3x = Activation('relu')(e3x)\n",
    "    squeeze = Conv2D(s1, kernel_size=(1, 1), padding='same')(e3x)\n",
    "    squeeze = Activation('relu')(squeeze)\n",
    "\n",
    "    # Upsampling and 3x3 Convolution to increase the number of filters\n",
    "    upsampled = UpSampling2D(size=(2, 2))(squeeze)\n",
    "    e3x_final = Conv2D(e3, kernel_size=(3, 3), padding='same')(upsampled)\n",
    "    e3x_final = Activation('relu')(e3x_final)\n",
    "\n",
    "    return e3x\n",
    "\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "def attention_gate(g, x, num_filters):\n",
    "    # Linear transformation of the gating signal\n",
    "    Wg = L.Conv2D(num_filters, (1, 1), padding=\"same\")(g)\n",
    "    Wg = L.BatchNormalization()(Wg)\n",
    "\n",
    "    # Linear transformation of the skip connection signal\n",
    "    Wx = L.Conv2D(num_filters, (1, 1), padding=\"same\")(x)\n",
    "    Wx = L.BatchNormalization()(Wx)\n",
    "    # Adding the transformed features together and applying ReLU activation\n",
    "    out = L.Activation(\"relu\")(L.Add()([Wg, Wx]))\n",
    "\n",
    "    # Transformation to compute the attention coefficients with sigmoid activation\n",
    "    out = L.Conv2D(1, (1, 1), padding=\"same\")(out)\n",
    "    out = L.Activation(\"sigmoid\")(out)\n",
    "    # Multiplying the attention coefficients with the original signal to get the attended signal\n",
    "    attended = L.Multiply()([out, x])\n",
    "\n",
    "    return attended\n",
    "def upsample_block(filters, squeeze, expand, strides, deconv_ksize, att_filters, inputs, skip_connection):\n",
    "  upconv = tf.keras.layers.Conv2DTranspose(filters, deconv_ksize, strides=strides, padding='same', kernel_initializer='he_normal')\n",
    "  d = upconv(inputs)\n",
    "\n",
    "  # Attention block\n",
    "  x = attention_gate(d, skip_connection, att_filters)\n",
    "\n",
    "  # Concatenate\n",
    "  d = tf.concat([x, d], axis=-1)\n",
    "\n",
    "  # Fire module\n",
    "  x = fire_module(d, squeeze, expand, expand)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006bb4f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.076825Z",
     "iopub.status.idle": "2024-05-16T06:30:44.077128Z",
     "shell.execute_reply": "2024-05-16T06:30:44.076989Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.076976Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "# Define the complete ATT Squeeze U-Net model\n",
    "def build_att_squeeze_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    C1 = Conv2D(64, (3, 3), strides=(2, 2), activation='relu', padding='same')(inputs)\n",
    "    P1 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(C1)\n",
    "    F2 = fire_module(P1, s1=16, e1=64, e3=64)\n",
    "    F3 = fire_module(F2, s1=16, e1=64, e3=64)\n",
    "    F4 = fire_module(F3, s1=32, e1=128, e3=128)\n",
    "    P2 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(F4)\n",
    "    F5 = fire_module(F4, s1=32, e1=128, e3=128)  \n",
    "    F6 = fire_module(F5, s1=48, e1=192, e3=192)  \n",
    "    F7 = fire_module(F6, s1=48, e1=192, e3=192)  \n",
    "    F8 = fire_module(F7, s1=64, e1=256, e3=256)\n",
    "    P3 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(F8)\n",
    "    #Bridge\n",
    "    F9 = fire_module(P3, s1=64, e1=256, e3=256) \n",
    "    C2 = Conv2D(2, (1, 1), activation='relu', padding='same')(F9) \n",
    "    C3 = Conv2D(1, (3, 3), activation='relu', padding='same')(C2)\n",
    "    # Decoder\n",
    "    # Attention Gates & DeFire Modules\n",
    "#     DeFire1 = desire_module(C3, s1=64, e3=256)\n",
    "#     CO1 = Concatenate(name='concat_with_ag1')([AG1, DeFire1])\n",
    "    upsampling_1 = upsample_block(filters=192, squeeze=48, expand=192, strides=(1, 1), deconv_ksize=3, att_filters=96,inputs=C3,skip_connection=P3)\n",
    "    C4 = Conv2D(1, (2, 2), activation='relu', padding='same')(upsampling_1)\n",
    "#     AG2 = attention_gate(g=F3, x=C4, num_filters=128)  \n",
    "#     DeFire2 = defire_module(AG2, s1=32, e3=128)\n",
    "#     CO2 = Concatenate(name='concat_with_ag1')([AG2, DeFire2])\n",
    "    upsampling_2 = upsample_block(filters=128, squeeze=32, expand=128, strides=(1, 1), deconv_ksize=3, att_filters=64,inputs=C4,skip_connection=P2)\n",
    "    C5 = Conv2D(1, (3, 3), activation='relu', padding='same')(upsampling_2)\n",
    "#     AG3 = attention_gate(g=C1, x=C5, num_filters=64) \n",
    "#     DeFire3 = defire_module(AG3, s1=16, e3=64)\n",
    "#     CO3 = Concatenate(name='concat_with_ag1')([AG3, DeFire3])\n",
    "    upsampling_2 = upsample_block(filters=64, squeeze=16, expand=64, strides=(2, 2), deconv_ksize=3, att_filters=16,inputs=C5,skip_connection=P1)\n",
    "    C6 = Conv2D(64, (3, 3), activation='relu', padding='same')(upsampling_2)\n",
    "\n",
    "    # Output\n",
    "    C7 = Conv2D(2, (1, 1), activation='relu', padding='same')(C6)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[C3])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (254, 254, 3) \n",
    "model = build_att_squeeze_unet(input_shape)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c29d1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.078007Z",
     "iopub.status.idle": "2024-05-16T06:30:44.078301Z",
     "shell.execute_reply": "2024-05-16T06:30:44.078164Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.078151Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "resized_images = []\n",
    "for img in images_loc:\n",
    "    resized_img = cv2.resize(img, (254,254))\n",
    "    resized_images.append(resized_img)\n",
    "resized_images = np.array(resized_images)\n",
    "X_train, X_testy, y_train, y_testy = train_test_split(resized_images, labels, test_size = 0.3)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_testy, y_testy, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5055e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.080408Z",
     "iopub.status.idle": "2024-05-16T06:30:44.080756Z",
     "shell.execute_reply": "2024-05-16T06:30:44.080609Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.080595Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_25_images(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c375ee",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.082517Z",
     "iopub.status.idle": "2024-05-16T06:30:44.082855Z",
     "shell.execute_reply": "2024-05-16T06:30:44.082708Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.082694Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_image = resized_images[3]\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d36715",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.084462Z",
     "iopub.status.idle": "2024-05-16T06:30:44.084935Z",
     "shell.execute_reply": "2024-05-16T06:30:44.084706Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.084688Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "model.fit(X_train, y_train,\n",
    "             batch_size=32,epochs=25,\n",
    "             validation_data=(X_val, y_val),\n",
    "             callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334617b2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.086198Z",
     "iopub.status.idle": "2024-05-16T06:30:44.086650Z",
     "shell.execute_reply": "2024-05-16T06:30:44.086423Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.086404Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "segmentation_mask = model.predict(test_image)\n",
    "\n",
    "# Threshold the segmentation mask to get binary mask\n",
    "threshold = 0.5  # You can adjust the threshold based on your requirements\n",
    "binary_mask = (segmentation_mask > threshold).astype(np.uint8)\n",
    "\n",
    "# Save the segmented image\n",
    "binary_mask_image = Image.fromarray(binary_mask[0, :, :, 0] * 255)\n",
    "binary_mask_image.save('segmented_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7dfda",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T06:30:44.087838Z",
     "iopub.status.idle": "2024-05-16T06:30:44.088148Z",
     "shell.execute_reply": "2024-05-16T06:30:44.088011Z",
     "shell.execute_reply.started": "2024-05-16T06:30:44.087999Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the original test image\n",
    "original_image = Image.open(\"/kaggle/working/segmented_image.jpg\")\n",
    "\n",
    "# Display the original test image and the segmented image side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(test_image)\n",
    "axes[0].set_title('Original Image')\n",
    "\n",
    "axes[1].imshow(original_image)  # Display the segmented image\n",
    "axes[1].set_title('Segmented Image')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2072281,
     "sourceId": 3440040,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.457255,
   "end_time": "2024-05-16T07:55:35.846305",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-16T07:55:31.389050",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
